{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97a671e9-fcd1-4154-a6fc-a430e368ebc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spend Categorization - RAG\n",
    "This notebook uses vector search to retrieve similar examples with spend categories. This is straight retrieval augmented generation context stuffing. We create a vector index with 7000 entries and search it to find the closest 5 neighbors, giving that to our model to make better decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27487c38-d073-483d-95ee-d49cf26a4583",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f45c1b64-f7f8-4f7a-bc9d-91205beda10f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM shm.spend.train\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfc352a6-f6ef-4933-9e15-6d8b6dd6de30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Our first 'algorithm' will be a simple vector search to provide similar examples from the categorized spend. This can be thought of as a semantic k nearest neighbour lookup. But it means we are always looking up our live, approved spend table to avoid mapping new categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93e9e33f-8ca2-439d-9974-0f28f19f1c41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE shm.spend.train\n",
    "SET TBLPROPERTIES (delta.enableChangeDataFeed = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "272e2332-a2d3-497c-9313-907a8a70e76a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "GTE (General Text Embeddings) is particularly well-suited for invoice text matching due to its ability to handle semantic variations and unstructured data. GTE's multi-stage contrastive learning enables robust interpretation of abbreviated vendor codes (e.g., \"ACME_CORP\" vs \"ACME Corp LLC\"), mismatched product descriptions (e.g., \"WIDGET-A2\" vs \"A2 Widget\"), and localized number formats (1,234.56 vs 1.234,56). Unlike models requiring structured input, GTE processes text sequences without relying on positional encoding. Additionally, GTE's optional sparse embeddings enable exact matching of critical identifiers.\n",
    "\n",
    "Because of the size of the table, the sync will take around 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b8c22c-53be-4dae-9004-93c2020675bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "client = VectorSearchClient()\n",
    "\n",
    "try:\n",
    "  index = client.create_delta_sync_index(\n",
    "    endpoint_name=\"one-env-shared-endpoint-3\",\n",
    "    source_table_name=\"shm.spend.train\",\n",
    "    index_name=\"shm.spend.vs_index\",\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key=\"id\",\n",
    "    embedding_source_column=\"combined_award_text\",\n",
    "    embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    "  )\n",
    "except:\n",
    "  print('index exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c72368a-b057-4e7e-95dd-e78bfde568f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's test out Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c9103d0-fdc1-4bea-8a92-96556d7ac7e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Vector search\n",
    "SELECT\n",
    "  FIRST(combined_award_text) as query_row,\n",
    "  STRING(\n",
    "    COLLECT_LIST(\n",
    "      CONCAT(\n",
    "        combined_award_text, '\\n', \n",
    "        'agency: ', funding_agency_name, '\\n',\n",
    "        'subagency: ', funding_sub_agency_name, '\\n\\n'\n",
    "      )\n",
    "    )\n",
    "  ) AS similarity_search\n",
    "FROM vector_search(\n",
    "  index => 'shm.spend.vs_index',\n",
    "  query_text => (\n",
    "    SELECT combined_award_text \n",
    "    FROM shm.spend.test \n",
    "    ORDER BY RAND() LIMIT 1\n",
    "  ),\n",
    "  num_results => 5,\n",
    "  query_type => 'hybrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb78e8ce-2a76-4b1d-a5bb-6e12e1aa7176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Use the following agency hierarchy and return the agency and subagency for the award information below. Return a json output with only the agencies. You must use the agencies and subagencies from the hierarchy, and pick the best ones. Never predict a subagency without the correct parent agency.\n",
    "\n",
    "Output format: \n",
    "{'agency': AGENCY_NAME, 'subagency': SUBAGENCY_NAME}\n",
    "\n",
    "Use the following examples for context:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e9cf91-6c50-49fb-b3d4-0caa0776f591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is our main query - we wrap in SQL to leverage our batch inference optimizations. We also enforce ontology by passing in an `enum` for the levels. This is a bit of an naive way to do this, but works well enough. I would quickly transition this to a tool call + agent framework to add some reflection and hierarchy testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c583f10f-72f7-4601-97f9-12e68e20980a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(\"agency_hierarchy.md\", \"r\") as f:\n",
    "    hierarchy = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebfb8baa-6a2a-49eb-8ea9-e41113415785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Optimized Vector search with preretrival\n",
    "SELECT\n",
    "  FIRST(combined_award_text) as query_row,\n",
    "  STRING(\n",
    "    COLLECT_LIST(\n",
    "      CONCAT(\n",
    "        combined_award_text, '\\n', \n",
    "        'agency: ', funding_agency_name, '\\n',\n",
    "        'subagency: ', funding_sub_agency_name, '\\n\\n'\n",
    "      )\n",
    "    )\n",
    "  ) AS similarity_search\n",
    "FROM vector_search(\n",
    "  index => 'shm.spend.vs_index',\n",
    "  query_text => (\n",
    "    SELECT combined_award_text \n",
    "    FROM shm.spend.test \n",
    "    ORDER BY RAND() LIMIT 1\n",
    "  ),\n",
    "  num_results => 5,\n",
    "  query_type => 'hybrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "560ae288-9d89-4d9a-b88c-057e7de08d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_generation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4b4ed44-9607-4086-be05-dd59d16187f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "if run_generation:\n",
    "    pred_vs_df = (\n",
    "        spark.table(\"shm.spend.test\")\n",
    "        .filter(F.col(\"combined_award_text\").isNotNull())  # Filter out nulls upfront\n",
    "        .filter(F.length(F.trim(F.col(\"combined_award_text\"))) > 0)  # Filter out empty strings\n",
    "        .withColumn(\n",
    "            \"vs_results\",\n",
    "            F.expr(\"\"\"\n",
    "                (\n",
    "                    SELECT\n",
    "                    STRING(\n",
    "                        COLLECT_LIST(\n",
    "                        CONCAT(\n",
    "                            combined_award_text, '\\n',\n",
    "                            'agency: ', funding_agency_name, '\\n',\n",
    "                            'subagency: ', funding_sub_agency_name, '\\n\\n'\n",
    "                        )\n",
    "                        )\n",
    "                    ) AS similarity_search\n",
    "                    FROM VECTOR_SEARCH(\n",
    "                    index => 'shm.spend.vs_index',\n",
    "                    query_text => combined_award_text,\n",
    "                    num_results => 5,\n",
    "                    query_type => 'hybrid'\n",
    "                    )\n",
    "                )\n",
    "            \"\"\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"full_prompt\",\n",
    "            F.concat(\n",
    "                F.lit(prompt), \n",
    "                F.lit('\\n'),\n",
    "                F.lit(hierarchy), \n",
    "                F.lit('\\n'),\n",
    "                F.col(\"vs_results\"),\n",
    "                F.lit(\"\\n Award to Classify: \\n\"),\n",
    "                F.col(\"combined_award_text\")\n",
    "            )\n",
    "        )\n",
    "        .select(\n",
    "            F.col(\"id\"),\n",
    "            F.col(\"full_prompt\"),\n",
    "            F.col(\"vs_results\"),\n",
    "            F.expr(\"\"\"\n",
    "                AI_QUERY(\n",
    "                    'databricks-meta-llama-3-3-70b-instruct',\n",
    "                    full_prompt,\n",
    "                    responseFormat => '{\n",
    "                        \"type\": \"json_schema\",\n",
    "                        \"json_schema\": {\n",
    "                            \"name\": \"categorization\",\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"agency\": {\"type\": \"string\"},\n",
    "                                    \"subagency\": {\"type\": \"string\"}\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }'\n",
    "                )\n",
    "            \"\"\").alias(\"llm_output\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pred_vs_df.write.mode(\"overwrite\").saveAsTable(\"shm.spend.pred_vectorsearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e106755e-4831-4957-ae74-d6f40e690d9b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764308100527}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_vs_df = spark.sql(\"SELECT * FROM shm.spend.pred_vectorsearch\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "239671f5-c07b-4669-a3c5-5f1e665cb85d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Add our spend and actuals back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de329e5f-f390-4394-92cb-695c77323fc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE shm.spend.pred_vectorsearch_comp AS\n",
    "SELECT\n",
    "  p.*,\n",
    "  agency,\n",
    "  subagency,\n",
    "  t.funding_agency_name,\n",
    "  t.funding_sub_agency_name,\n",
    "  t.federal_action_obligation as spend\n",
    "FROM \n",
    "  shm.spend.pred_vectorsearch p\n",
    "JOIN\n",
    "  shm.spend.test t\n",
    "ON \n",
    "  t.id = p.id\n",
    "LATERAL VIEW \n",
    "  JSON_TUPLE(p.llm_output, 'agency', 'subagency') AS agency, subagency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16749e1-762d-42c8-b336-098605bc1e8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation\n",
    "The cells below evaluate the results, weighted by spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e66e0e47-c245-4bc6-8648-61cc202c5832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_vs_comp = spark.table('shm.spend.pred_vectorsearch_comp').dropna(\n",
    "    subset=['funding_agency_name', 'agency', 'funding_sub_agency_name', 'subagency']\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3282bebe-2301-47fc-8092-161e16f09519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Even with only 7,000 rows (negligble in most spend categorization cases), we've improved level 1 accuracy from 53% to 96% and level 2 accuracy from 26% to 92%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7720af2f-001d-4ed0-a5bd-4570eb652ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(f\"\"\"Agency Accuracy: {accuracy_score(\n",
    "  pred_vs_comp['funding_agency_name'], \n",
    "  pred_vs_comp['agency']\n",
    "  ):0.3f}\"\"\")\n",
    "\n",
    "print(f\"\"\"Subagency Accuracy: {accuracy_score(\n",
    "  pred_vs_comp['funding_sub_agency_name'], \n",
    "  pred_vs_comp['subagency']\n",
    "  ):0.3f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd4dcd5-1e02-4435-bc7c-39ac967a9a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class_dict = classification_report(\n",
    "  y_true = pred_vs_comp['funding_agency_name'], \n",
    "  y_pred = pred_vs_comp['agency'],\n",
    "  sample_weight=pred_vs_comp['spend'].abs(),\n",
    "  output_dict=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1890e39-04e9-4a82-90ba-6e381c868d26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60d1eff7-a374-48fb-8fdf-bec3b7e0a2c2",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764348641386}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    pd.DataFrame(class_dict)\n",
    "      .transpose()\n",
    "      .reset_index()\n",
    "      .drop(columns=['f1-score'], errors='ignore')\n",
    "      .rename(columns={'support': 'spend'})\n",
    "      .sort_values('spend', ascending=False)\n",
    "      .query('index != [\"accuracy\", \"weighted avg\", \"macro avg\"]')\n",
    "      .assign(spend=lambda df: (df['spend'] / 1000).round().astype(int))\n",
    "      .round(2)\n",
    "      .head(12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b2767c-e92d-4636-a9ef-7937834b4914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the data\n",
    "df = pd.DataFrame(class_dict).transpose().reset_index()\n",
    "df = df.query('index != [\"accuracy\", \"weighted avg\", \"macro avg\"]')\n",
    "df = df.sort_values('support', ascending=False)\n",
    "\n",
    "# Add total spend as a label on each bar\n",
    "df['total_spend'] = df['index'].map(pred_vs_comp.groupby('funding_agency_name')['spend'].sum().round(0))\n",
    "\n",
    "# Truncate labels to max 20 characters\n",
    "df['short_label'] = df['index'].str.slice(0, 20)\n",
    "\n",
    "# Sort by total spend descending\n",
    "df = df.sort_values('total_spend', ascending=False).reset_index(drop=True).head(9)\n",
    "\n",
    "# Set the theme to minimal\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create the bar plot for precision with total spend labels inside bars\n",
    "plt.figure(figsize=(12, 8))  # Increased height for taller bars\n",
    "barplot = sns.barplot(x='short_label', y='precision', data=df, color='#1B3139')\n",
    "plt.xlabel('', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.ylim(0.5,1.0)\n",
    "\n",
    "for spine in barplot.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Rotate x labels for better readability\n",
    "plt.xticks(rotation=-60, ha='left')\n",
    "\n",
    "barplot.grid(False)\n",
    "\n",
    "# Add rotated spend labels inside each bar\n",
    "for index, row in df.iterrows():\n",
    "    barplot.text(index, row.precision*0.8, f\"${row.total_spend:,.0f}\", color='white', ha=\"center\", va='baseline', rotation=-90, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('vector_search.png', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2774411577120131,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "2_batch_vector_search",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
