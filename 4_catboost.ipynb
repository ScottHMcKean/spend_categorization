{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b8071b-b3d0-4045-b4cd-1968232a0af0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spend Categorizaton - CatBoost\n",
    "This notebook trains a CatBoost model on top of the existing spend data. The goal here is to replicate historical categorization and always be rebuilding a model off the corrected 'gold' table of categorization, so that if managers correct spend, it is automatically reflected in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b00d49f-1985-4365-8626-cb8cecf0a530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook requires a decently sized classic cluster to run and will not work on Serverless due to the size of the dataset (800k rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeca69b0-ba3a-4ef5-a4c9-78ba6d6bb192",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install catboost\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b4b2650-34d1-41bc-8026-6fa44658bf92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from mlflow.models import infer_signature\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff23a1d1-2739-41a9-8c0c-0bdec9c6516e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_pd = spark.table('shm.spend.train').toPandas()\n",
    "train_pd['year'] = train_pd.action_date.dt.year\n",
    "train_pd['month'] = train_pd.action_date.dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aee6f45-6e90-468c-a859-3fc177e3b31d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is traditional machine learning, where we use all the text columns from orders as features and the levels as targets. But it requires a bit of complexity because we need to have one model PER target, since the targets are sequential. This also leads to error propogation so we must be careful to watch for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffe0bbef-9b11-41b5-9099-1d88c661db1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_feature_cols = [\n",
    "    'contract_award_unique_key', 'action_date', 'recipient_name_raw',\n",
    "    'recipient_state_name', 'recipient_city_name',\n",
    "    'transaction_description', 'product_or_service_code_description',\n",
    "    'naics_description', 'usaspending_permalink', \n",
    "  ]\n",
    "\n",
    "num_feature_cols = [\n",
    "  'federal_action_obligation',\n",
    "  'base_and_all_options_value', \n",
    "]\n",
    "\n",
    "for col_name in cat_feature_cols:\n",
    "  train_pd[col_name] = train_pd[col_name].astype(str)\n",
    "\n",
    "targets = [\n",
    "  'funding_agency_name', 'funding_sub_agency_name'\n",
    "  ]\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "for targ_name in targets:\n",
    "  train_pd[targ_name] = train_pd[targ_name].astype(str)\n",
    "\n",
    "X = train_pd[cat_feature_cols + num_feature_cols]\n",
    "y = train_pd[targets]\n",
    "\n",
    "# We use the term 'validation' because we have a hold out test set already\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "  X, y, test_size=0.2, random_state=42\n",
    "  )\n",
    "\n",
    "# Keep train / test splits consistent\n",
    "y_train_lvl_1 = y_train['funding_agency_name']\n",
    "y_val_lvl_1 = y_val['funding_agency_name']\n",
    "y_train_lvl_2 = y_train['funding_sub_agency_name']\n",
    "y_val_lvl_2 = y_val['funding_sub_agency_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aecc6f6b-b724-409c-a238-499ad197220e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Level 1 Model\n",
    "This is out first model, due to the large dataset we only do 5 iterations, but could easily train this longer and do hyperparameter tuning to improve performance. The `Pool` is a CatBoost artifact to help it distribute training across CPUs and improve throughput, similar to Tensors in pytorch etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66a39882-dba4-4445-8a63-64601bd3570c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri('databricks-uc')\n",
    "train_lvl_1 = False\n",
    "train_lvl_2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05ca7284-111e-45c7-b792-1047e99788f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if train_lvl_1:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.sklearn.autolog()\n",
    "\n",
    "        params = {\n",
    "            'iterations': 1000,\n",
    "            'learning_rate': 0.1,\n",
    "            'depth': 6,\n",
    "            'l2_leaf_reg': 3,\n",
    "            'colsample_bylevel': 0.8,\n",
    "            'early_stopping_rounds': 50,\n",
    "            'verbose': 100\n",
    "        }\n",
    "\n",
    "        model_lvl1 = CatBoostClassifier(**params)\n",
    "\n",
    "        # Create CatBoost Pool for efficient memory handling\n",
    "        train_pool = Pool(X_train, y_train_lvl_1, cat_features=cat_feature_cols)\n",
    "        val_pool = Pool(X_val, y_val_lvl_1, cat_features=cat_feature_cols)\n",
    "\n",
    "        model_lvl1.fit(\n",
    "            train_pool,\n",
    "            eval_set=val_pool,\n",
    "            use_best_model=True,\n",
    "            task_type=\"GPU\"\n",
    "        )\n",
    "\n",
    "        mlflow.catboost.log_model(\n",
    "            cb_model=model_lvl1,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=\"shm.spend.agency_model\",\n",
    "            signature=mlflow.models.infer_signature(\n",
    "                X_train, \n",
    "                model_lvl1.predict(X_train)\n",
    "                )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12214fd3-b44f-4de8-959c-84e93bf687f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here we log the model so we can reload for inference and downstream tasks. We can also serve this model to make the inference process much easier. In practice, we would log all four models (Level 1 --> Level 4) and wrap them in a single `pyfunc` model class under a serving endpoint. This would provide a convenient way to call the latest model without changing code or anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f13d681-1a1c-4f27-9399-759db71c82dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow# Test our model reload\n",
    "model_lvl1 = mlflow.catboost.load_model(\"models:/shm.spend.agency_model/1\")\n",
    "model_lvl1.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9d6bd6f-8716-452f-8852-73dfcb1421a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Level 2 Model\n",
    "Same story as above, but instead we are first taking the prediction from Level 1 as a feature into the Level 2 model. This is what creates the error propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed926c01-07d1-4af4-8ed5-67d7fde73632",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get predictions and probabilities for Level 1\n",
    "pred_train_lvl1 = model_lvl1.predict(X_train)\n",
    "proba_train_lvl1 = model_lvl1.predict_proba(X_train)\n",
    "pred_val_lvl1 = model_lvl1.predict(X_val)\n",
    "proba_val_lvl1 = model_lvl1.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37685b27-2d39-4275-b111-980e1708131a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Augment the training and validation data\n",
    "X_train_lvl_2 = X_train.copy()\n",
    "X_train_lvl_2['funding_agency_name'] = pred_train_lvl1.ravel()\n",
    "\n",
    "X_val_lvl_2 = X_val.copy()\n",
    "X_val_lvl_2['funding_agency_name'] = pred_val_lvl1.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14fdd526-f2e7-49f7-b303-62bcb5ad4582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_lvl_2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "503cda34-06a7-4a84-b376-4cd82e861ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if train_lvl_2:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.sklearn.autolog()\n",
    "        \n",
    "        # Filter validation set to only include classes present in training set\n",
    "        train_classes = set(y_train_lvl_2.unique())\n",
    "        val_mask = y_val_lvl_2.isin(train_classes)\n",
    "        \n",
    "        X_val_lvl_2_filtered = X_val_lvl_2[val_mask]\n",
    "        y_val_lvl_2_filtered = y_val_lvl_2[val_mask]\n",
    "        \n",
    "        print(f\"Filtered out {(~val_mask).sum()} validation samples with unseen classes\")\n",
    "        print(f\"Validation set size: {len(y_val_lvl_2_filtered)} samples\")\n",
    "\n",
    "        params = {\n",
    "            'loss_function': 'MultiClass',\n",
    "            'iterations': 200,\n",
    "            'learning_rate': 0.3,\n",
    "            'depth': 4,\n",
    "            'l2_leaf_reg': 3,\n",
    "            'colsample_bylevel': 0.5,\n",
    "            'early_stopping_rounds': 20,\n",
    "            'bootstrap_type': 'Bernoulli',\n",
    "            'subsample': 0.7,\n",
    "            'one_hot_max_size': 4,\n",
    "            'border_count': 64,\n",
    "            'early_stopping_rounds': 20,\n",
    "            'verbose': 100\n",
    "        }\n",
    "\n",
    "        model_lvl2 = CatBoostClassifier(**params)\n",
    "\n",
    "        # Create CatBoost Pool for efficient memory handling\n",
    "        train_pool = Pool(\n",
    "            X_train_lvl_2, \n",
    "            y_train_lvl_2, \n",
    "            cat_features=cat_feature_cols + ['funding_agency_name']\n",
    "        )\n",
    "\n",
    "        val_pool = Pool(\n",
    "            X_val_lvl_2_filtered, \n",
    "            y_val_lvl_2_filtered, \n",
    "            cat_features=cat_feature_cols + ['funding_agency_name']\n",
    "        )\n",
    "\n",
    "        model_lvl2.fit(\n",
    "            train_pool,\n",
    "            eval_set=val_pool,\n",
    "            use_best_model=True\n",
    "        )\n",
    "\n",
    "        mlflow.catboost.log_model(\n",
    "            cb_model=model_lvl2,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=\"shm.spend.subagency_model\",\n",
    "            signature=mlflow.models.infer_signature(\n",
    "                X_val_lvl_2_filtered, \n",
    "                model_lvl2.predict(X_val_lvl_2_filtered)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93c4c2ec-3348-46f8-8686-556e89ffa1aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation\n",
    "Here we are going to look at the validation predictions for accuracy, first predicting Level 1 then Level 2. In production we would have four levels of prediction and wrap some of the boilerplate in a library. For now, we will reload the models (could use Aliases etc. too) and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a53504-9003-46aa-aa93-57a0499182ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri('databricks-uc')\n",
    "model_lvl1 = mlflow.catboost.load_model(\"models:/shm.spend.agency_model/1\")\n",
    "model_lvl2 = mlflow.catboost.load_model(\"models:/shm.spend.subagency_model/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "220c08da-c221-48ee-a194-d3fc85c67a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_val_eval = X_val.copy()\n",
    "X_val_eval['agency'] = model_lvl1.predict(X_val).ravel()\n",
    "\n",
    "# Add the level 1 prediction as a feature for level 2 model\n",
    "X_val_eval_lvl2 = X_val.copy()\n",
    "X_val_eval_lvl2['funding_agency_name'] = X_val_eval['agency']\n",
    "\n",
    "# Create Pool with categorical features for level 2 prediction\n",
    "val_pool_eval = Pool(\n",
    "    X_val_eval_lvl2,\n",
    "    cat_features=cat_feature_cols + ['funding_agency_name']\n",
    ")\n",
    "\n",
    "X_val_eval['subagency'] = model_lvl2.predict(val_pool_eval).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "661a3787-b72c-48c9-ae12-c95e7f0a3dd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_val_eval.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e394b4fe-240d-4786-ae28-47d14bd98913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The real test is the holdout Test Predictions. We load our test set and use the trained models on data that they've never seen to get a better accuracy metric. If the models aren't overfit, we expect similar out of sample performance to the numbers above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92d12001-6afc-47be-93e5-5eef59761d35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_pd = spark.table('shm.spend.test').toPandas()\n",
    "test_pd['year'] = test_pd.action_date.dt.year\n",
    "test_pd['month'] = test_pd.action_date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "554da5e6-34ff-4d1e-be05-c94ae54df06d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test = test_pd[cat_feature_cols + num_feature_cols].copy()\n",
    "\n",
    "# Convert categorical features to string (same as training)\n",
    "for col_name in cat_feature_cols:\n",
    "    X_test[col_name] = X_test[col_name].astype(str)\n",
    "\n",
    "# Now make predictions\n",
    "X_test['funding_agency_name'] = model_lvl1.predict(X_test).ravel()\n",
    "\n",
    "# Create Pool for level 2 prediction with categorical features specified\n",
    "test_pool_lvl2 = Pool(\n",
    "    X_test,\n",
    "    cat_features=cat_feature_cols + ['funding_agency_name']\n",
    ")\n",
    "\n",
    "X_test['funding_sub_agency_name'] = model_lvl2.predict(test_pool_lvl2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dbd34e3-90cf-44c8-9a4d-ba4d3d8c15ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    spark.createDataFrame(X_test)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(\"shm.spend.pred_catboost\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0d259a-1a18-41d5-b00b-9043451aec48",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"usaspending_permalink\":{\"format\":{\"preset\":\"string-preset-url\",\"locale\":\"en\"}}}},\"syncTimestamp\":1764347817138}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_vs_df = spark.sql(\"SELECT * FROM shm.spend.pred_catboost\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f54be4b3-9249-44a0-99c1-f0f6ee9ba05d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE shm.spend.pred_catboost_comp AS\n",
    "SELECT\n",
    "  t.*,\n",
    "  p.funding_agency_name as agency,\n",
    "  p.funding_sub_agency_name as subagency,\n",
    "  t.federal_action_obligation as spend\n",
    "FROM \n",
    "  shm.spend.pred_catboost p\n",
    "JOIN\n",
    "  shm.spend.test t\n",
    "ON \n",
    "  t.contract_award_unique_key = p.contract_award_unique_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e89a8b54-8a3e-4333-a48d-6ac5f81cedef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_catboost_comp = spark.table('shm.spend.pred_catboost_comp').dropna(\n",
    "    subset=['funding_agency_name', 'agency', 'funding_sub_agency_name', 'subagency']\n",
    ").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9976e196-4d03-43cd-abdc-035d96fdf6dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The catboost model only trained on 7,000 rows but was still able to improve accuracy to 94% on level 1 and 90% on level 2. There is a lot more optimization that could be done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5eac046-b92d-4a73-ac23-48497fa1bd40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(f\"\"\"Agency Accuracy: {accuracy_score(\n",
    "  pred_catboost_comp['funding_agency_name'], \n",
    "  pred_catboost_comp['agency']\n",
    "  ):0.3f}\"\"\")\n",
    "\n",
    "print(f\"\"\"Subagency Accuracy: {accuracy_score(\n",
    "  pred_catboost_comp['funding_sub_agency_name'], \n",
    "  pred_catboost_comp['subagency']\n",
    "  ):0.3f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03f2b86c-bfc3-423c-987c-ded9cd871267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class_dict = classification_report(\n",
    "  y_true = pred_catboost_comp['funding_agency_name'], \n",
    "  y_pred = pred_catboost_comp['agency'],\n",
    "  sample_weight=pred_catboost_comp['spend'].abs(),\n",
    "  output_dict=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "492c215e-4e0c-41a4-8b58-db04c0556dec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    pd.DataFrame(class_dict)\n",
    "      .transpose()\n",
    "      .reset_index()\n",
    "      .drop(columns=['f1-score'], errors='ignore')\n",
    "      .rename(columns={'support': 'spend'})\n",
    "      .sort_values('spend', ascending=False)\n",
    "      .query('index != [\"accuracy\", \"weighted avg\", \"macro avg\"]')\n",
    "      .assign(spend=lambda df: (df['spend'] / 1000).round().astype(int))\n",
    "      .round(2)\n",
    "      .head(12)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07486997-2760-486e-a7f7-0d8cfdd2f181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the data\n",
    "df = pd.DataFrame(class_dict).transpose().reset_index()\n",
    "df = df.query('index != [\"accuracy\", \"weighted avg\", \"macro avg\"]')\n",
    "df = df.sort_values('support', ascending=False)\n",
    "\n",
    "# Add total spend as a label on each bar\n",
    "df['total_spend'] = df['index'].map(pred_vs_comp.groupby('funding_agency_name')['spend'].sum().round(0))\n",
    "\n",
    "# Truncate labels to max 20 characters\n",
    "df['short_label'] = df['index'].str.slice(0, 20)\n",
    "\n",
    "# Sort by total spend descending\n",
    "df = df.sort_values('total_spend', ascending=False).reset_index(drop=True).head(9)\n",
    "\n",
    "# Set the theme to minimal\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Create the bar plot for precision with total spend labels inside bars\n",
    "plt.figure(figsize=(12, 8))  # Increased height for taller bars\n",
    "barplot = sns.barplot(x='short_label', y='precision', data=df, color='#1B3139')\n",
    "plt.xlabel('', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.ylim(0.5,1.0)\n",
    "\n",
    "for spine in barplot.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "# Rotate x labels for better readability\n",
    "plt.xticks(rotation=-60, ha='left')\n",
    "\n",
    "barplot.grid(False)\n",
    "\n",
    "# Add rotated spend labels inside each bar\n",
    "for index, row in df.iterrows():\n",
    "    barplot.text(index, row.precision*0.8, f\"${row.total_spend:,.0f}\", color='white', ha=\"center\", va='baseline', rotation=-90, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('catboost.png', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2774411577118351,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "4_catboost",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
