{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97a671e9-fcd1-4154-a6fc-a430e368ebc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spend Categorization - Vector Search RAG\n",
    "\n",
    "This notebook uses vector search for Borealis Wind Systems spend categorization. We create a vector index from labeled invoices and retrieve similar examples to provide context for LLM classification.\n",
    "\n",
    "**Approach:**\n",
    "1. Build a vector index from `invoices_enh` (enhanced with LLM descriptions)\n",
    "2. For each transaction, retrieve 5 similar examples with known categories\n",
    "3. Use these examples as few-shot context for classification\n",
    "\n",
    "Tested on Serverless v4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27487c38-d073-483d-95ee-d49cf26a4583",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install uv\n",
    "%uv pip install .\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e107cbff-b65a-4598-8eaf-61160b4da8bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import get_spark\n",
    "from src.config import load_config\n",
    "\n",
    "spark = get_spark()\n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f45c1b64-f7f8-4f7a-bc9d-91205beda10f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Widgets for SQL cells\n",
    "dbutils.widgets.removeAll()\n",
    "dbutils.widgets.text(\"catalog\", config.catalog)\n",
    "dbutils.widgets.text(\"schema\", config.schema_name)\n",
    "dbutils.widgets.text(\"invoices\", config.invoices)\n",
    "dbutils.widgets.text(\"cat_vectorsearch\", config.cat_vectorsearch_table)\n",
    "\n",
    "# Preview the enhanced invoices table\n",
    "display(spark.table(config.full_invoices_table_path).limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfc352a6-f6ef-4933-9e15-6d8b6dd6de30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Combined Text Column\n",
    "\n",
    "First, we create a combined text column for embedding that captures the key information about each transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93e9e33f-8ca2-439d-9974-0f28f19f1c41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a table with combined text for vector search\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE {config.catalog}.{config.schema_name}.invoices_vs AS\n",
    "SELECT \n",
    "    *,\n",
    "    CONCAT(\n",
    "        'Supplier: ', COALESCE(supplier, ''), ' | ',\n",
    "        'Country: ', COALESCE(supplier_country, ''), ' | ',\n",
    "        'Description: ', COALESCE(description, ''), ' | ',\n",
    "        'Plant: ', COALESCE(plant, ''), ' | ',\n",
    "        'Region: ', COALESCE(region, ''), ' | ',\n",
    "        'Cost Centre: ', COALESCE(cost_centre, '')\n",
    "    ) AS combined_text\n",
    "FROM {config.full_invoices_table_path}\n",
    "\"\"\")\n",
    "\n",
    "# Enable Change Data Feed for vector search sync\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {config.catalog}.{config.schema_name}.invoices_vs\n",
    "SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "272e2332-a2d3-497c-9313-907a8a70e76a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Vector Search Index\n",
    "\n",
    "GTE (General Text Embeddings) handles semantic variations well - matching \"ACME_CORP\" with \"ACME Corp LLC\" or interpreting different description formats. We use `databricks-gte-large-en` for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b8c22c-53be-4dae-9004-93c2020675bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "client = VectorSearchClient()\n",
    "\n",
    "# Create or update the vector search index\n",
    "try:\n",
    "    index = client.create_delta_sync_index(\n",
    "        endpoint_name=\"one-env-shared-endpoint-3\",  # Update with your endpoint\n",
    "        source_table_name=f\"{config.catalog}.{config.schema_name}.invoices_vs\",\n",
    "        index_name=f\"{config.catalog}.{config.schema_name}.vs_index\",\n",
    "        pipeline_type=\"TRIGGERED\",\n",
    "        primary_key=\"order_id\",\n",
    "        embedding_source_column=\"combined_text\",\n",
    "        embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    "    )\n",
    "    print(\"✅ Vector search index created\")\n",
    "except Exception as e:\n",
    "    print(f\"Index exists or error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c72368a-b057-4e7e-95dd-e78bfde568f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test Vector Search\n",
    "\n",
    "Query the index to find similar invoices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c9103d0-fdc1-4bea-8a92-96556d7ac7e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test vector search with a random transaction\n",
    "test_query = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  FIRST(combined_text) as query_row,\n",
    "  STRING(\n",
    "    COLLECT_LIST(\n",
    "      CONCAT(\n",
    "        combined_text, '\\n', \n",
    "        'Level 1: ', category_level_1, '\\n',\n",
    "        'Level 2: ', category_level_2, '\\n',\n",
    "        'Level 3: ', category_level_3, '\\n\\n'\n",
    "      )\n",
    "    )\n",
    "  ) AS similar_examples\n",
    "FROM vector_search(\n",
    "  index => '{config.catalog}.{config.schema_name}.vs_index',\n",
    "  query_text => (\n",
    "    SELECT combined_text \n",
    "    FROM {config.catalog}.{config.schema_name}.invoices_vs \n",
    "    ORDER BY RAND() LIMIT 1\n",
    "  ),\n",
    "  num_results => 5,\n",
    "  query_type => 'hybrid'\n",
    ")\n",
    "\"\"\")\n",
    "display(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb78e8ce-2a76-4b1d-a5bb-6e12e1aa7176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a spend categorization expert for Borealis Wind Systems, a wind turbine manufacturer.\n",
    "\n",
    "Classify the transaction into the correct 3-level category hierarchy:\n",
    "- Level 1: Direct, Indirect, or Non-Procureable\n",
    "- Level 2: The category (e.g., \"Bearings & Seals\", \"MRO\", \"IT & Software\")\n",
    "- Level 3: The specific item type (e.g., \"Spherical roller bearing\", \"Tool rental\")\n",
    "\n",
    "Use ONLY categories from the hierarchy provided. Match the transaction to the most specific and accurate category.\n",
    "\n",
    "Use the following similar examples for context:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80e9cf91-6c50-49fb-b3d4-0caa0776f591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Category Hierarchy\n",
    "\n",
    "Load the category hierarchy from config for use in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c583f10f-72f7-4601-97f9-12e68e20980a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load hierarchy from config.yaml\n",
    "category_descriptions = config.get_category_descriptions()\n",
    "\n",
    "# Format hierarchy as text for the prompt\n",
    "def format_hierarchy(categories):\n",
    "    lines = []\n",
    "    for level1, level2_dict in categories.items():\n",
    "        lines.append(f\"\\n## {level1}\")\n",
    "        for level2, level3_list in level2_dict.items():\n",
    "            desc = category_descriptions.get(level2, \"\")\n",
    "            lines.append(f\"  - {level2}: {desc}\")\n",
    "            for level3 in level3_list:\n",
    "                lines.append(f\"      - {level3}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "hierarchy = format_hierarchy(config.categories)\n",
    "print(hierarchy[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebfb8baa-6a2a-49eb-8ea9-e41113415785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create train/test split for evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "invoices_df = spark.table(f'{config.catalog}.{config.schema_name}.invoices_vs').toPandas()\n",
    "train_df, test_df = train_test_split(invoices_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "# Save test set for evaluation\n",
    "spark.createDataFrame(test_df).write.mode(\"overwrite\").saveAsTable(f\"{config.catalog}.{config.schema_name}.test_vs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "560ae288-9d89-4d9a-b88c-057e7de08d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_generation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4b4ed44-9607-4086-be05-dd59d16187f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "if run_generation:\n",
    "    pred_vs_df = (\n",
    "        spark.table(f\"{config.catalog}.{config.schema_name}.test_vs\")\n",
    "        .filter(F.col(\"combined_text\").isNotNull())\n",
    "        .filter(F.length(F.trim(F.col(\"combined_text\"))) > 0)\n",
    "        .withColumn(\n",
    "            \"vs_results\",\n",
    "            F.expr(f\"\"\"\n",
    "                (\n",
    "                    SELECT\n",
    "                    STRING(\n",
    "                        COLLECT_LIST(\n",
    "                        CONCAT(\n",
    "                            combined_text, '\\n',\n",
    "                            'Level 1: ', category_level_1, '\\n',\n",
    "                            'Level 2: ', category_level_2, '\\n',\n",
    "                            'Level 3: ', category_level_3, '\\n\\n'\n",
    "                        )\n",
    "                        )\n",
    "                    ) AS similar_examples\n",
    "                    FROM VECTOR_SEARCH(\n",
    "                    index => '{config.catalog}.{config.schema_name}.vs_index',\n",
    "                    query_text => combined_text,\n",
    "                    num_results => 5,\n",
    "                    query_type => 'hybrid'\n",
    "                    )\n",
    "                )\n",
    "            \"\"\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"full_prompt\",\n",
    "            F.concat(\n",
    "                F.lit(prompt), \n",
    "                F.lit('\\n\\nCategory Hierarchy:\\n'),\n",
    "                F.lit(hierarchy), \n",
    "                F.lit('\\n\\nSimilar Examples:\\n'),\n",
    "                F.col(\"vs_results\"),\n",
    "                F.lit(\"\\n\\nTransaction to Classify:\\n\"),\n",
    "                F.col(\"combined_text\")\n",
    "            )\n",
    "        )\n",
    "        .select(\n",
    "            F.col(\"order_id\"),\n",
    "            F.col(\"category_level_1\").alias(\"actual_level_1\"),\n",
    "            F.col(\"category_level_2\").alias(\"actual_level_2\"),\n",
    "            F.col(\"category_level_3\").alias(\"actual_level_3\"),\n",
    "            F.col(\"total\"),\n",
    "            F.col(\"full_prompt\"),\n",
    "            F.col(\"vs_results\"),\n",
    "            F.expr(f\"\"\"\n",
    "                AI_QUERY(\n",
    "                    '{config.large_llm_endpoint}',\n",
    "                    full_prompt,\n",
    "                    responseFormat => '{{\n",
    "                        \"type\": \"json_schema\",\n",
    "                        \"json_schema\": {{\n",
    "                            \"name\": \"categorization\",\n",
    "                            \"schema\": {{\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {{\n",
    "                                    \"level_1\": {{\"type\": \"string\"}},\n",
    "                                    \"level_2\": {{\"type\": \"string\"}},\n",
    "                                    \"level_3\": {{\"type\": \"string\"}}\n",
    "                                }}\n",
    "                            }}\n",
    "                        }}\n",
    "                    }}'\n",
    "                )\n",
    "            \"\"\").alias(\"llm_output\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    pred_vs_df.write.mode(\"overwrite\").saveAsTable(config.full_cat_vectorsearch_table_path)\n",
    "    print(f\"✅ Predictions saved to {config.full_cat_vectorsearch_table_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e106755e-4831-4957-ae74-d6f40e690d9b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764308100527}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_vs_df = spark.sql(f\"SELECT * FROM {config.full_cat_vectorsearch_table_path}\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "239671f5-c07b-4669-a3c5-5f1e665cb85d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Parse LLM Output and Prepare for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de329e5f-f390-4394-92cb-695c77323fc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parse LLM output and create comparison table\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TABLE {config.catalog}.{config.schema_name}.cat_vectorsearch_comp AS\n",
    "SELECT\n",
    "  p.order_id,\n",
    "  p.actual_level_1,\n",
    "  p.actual_level_2,\n",
    "  p.actual_level_3,\n",
    "  p.total,\n",
    "  pred_level_1,\n",
    "  pred_level_2,\n",
    "  pred_level_3\n",
    "FROM \n",
    "  {config.full_cat_vectorsearch_table_path} p\n",
    "LATERAL VIEW \n",
    "  JSON_TUPLE(p.llm_output, 'level_1', 'level_2', 'level_3') AS pred_level_1, pred_level_2, pred_level_3\n",
    "\"\"\")\n",
    "print(\"✅ Comparison table created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c16749e1-762d-42c8-b336-098605bc1e8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluation\n",
    "The cells below evaluate the results, weighted by spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e66e0e47-c245-4bc6-8648-61cc202c5832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pred_vs_comp = spark.table(f'{config.catalog}.{config.schema_name}.cat_vectorsearch_comp').dropna(\n",
    "    subset=['actual_level_1', 'pred_level_1', 'actual_level_2', 'pred_level_2']\n",
    ").toPandas()\n",
    "\n",
    "print(f\"Evaluation dataset: {len(pred_vs_comp)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3282bebe-2301-47fc-8092-161e16f09519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Accuracy Results\n",
    "\n",
    "Compare vector search RAG predictions against actuals, weighted by spend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7720af2f-001d-4ed0-a5bd-4570eb652ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(f\"Level 1 Accuracy (Direct/Indirect/Non-Procureable): {accuracy_score(pred_vs_comp['actual_level_1'], pred_vs_comp['pred_level_1']):0.3f}\")\n",
    "print(f\"Level 2 Accuracy (Category): {accuracy_score(pred_vs_comp['actual_level_2'], pred_vs_comp['pred_level_2']):0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd4dcd5-1e02-4435-bc7c-39ac967a9a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Classification report for Level 2 categories, weighted by spend\n",
    "class_dict = classification_report(\n",
    "    y_true=pred_vs_comp['actual_level_2'], \n",
    "    y_pred=pred_vs_comp['pred_level_2'],\n",
    "    sample_weight=pred_vs_comp['total'].abs(),\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1890e39-04e9-4a82-90ba-6e381c868d26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60d1eff7-a374-48fb-8fdf-bec3b7e0a2c2",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764348641386}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display classification metrics by category, sorted by spend\n",
    "metrics_df = (\n",
    "    pd.DataFrame(class_dict)\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'category', 'support': 'spend'})\n",
    "    .query('category not in [\"accuracy\", \"weighted avg\", \"macro avg\"]')\n",
    "    .sort_values('spend', ascending=False)\n",
    "    .assign(spend=lambda df: (df['spend'] / 1000).round().astype(int))\n",
    "    .round(2)\n",
    "    .head(15)\n",
    ")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b2767c-e92d-4636-a9ef-7937834b4914",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare visualization data\n",
    "df = pd.DataFrame(class_dict).transpose().reset_index()\n",
    "df = df.query('index not in [\"accuracy\", \"weighted avg\", \"macro avg\"]')\n",
    "df = df.sort_values('support', ascending=False)\n",
    "\n",
    "# Add total spend by category\n",
    "spend_by_cat = pred_vs_comp.groupby('actual_level_2')['total'].sum()\n",
    "df['total_spend'] = df['index'].map(spend_by_cat).fillna(0)\n",
    "\n",
    "# Truncate labels to max 20 characters\n",
    "df['short_label'] = df['index'].str.slice(0, 20)\n",
    "\n",
    "# Sort by total spend descending\n",
    "df = df.sort_values('total_spend', ascending=False).reset_index(drop=True).head(10)\n",
    "\n",
    "# Create visualization\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "barplot = sns.barplot(x='short_label', y='precision', data=df, color='#2E86AB')\n",
    "plt.xlabel('', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Vector Search RAG Precision by Category (Borealis Wind)', fontsize=16)\n",
    "plt.ylim(0.5, 1.0)\n",
    "\n",
    "for spine in barplot.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.xticks(rotation=-45, ha='left')\n",
    "barplot.grid(False)\n",
    "\n",
    "# Add spend labels inside bars\n",
    "for i, row in df.reset_index().iterrows():\n",
    "    if row.total_spend > 0:\n",
    "        barplot.text(i, row.precision * 0.85, f\"${row.total_spend/1e6:.1f}M\", \n",
    "                     color='white', ha=\"center\", va='baseline', rotation=-90, \n",
    "                     fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vector_search.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2774411577120131,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "5_vectorsearch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
